{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4-DCtP9CQXh"
      },
      "source": [
        "CycleGAN \\\\\n",
        "Kasra Borazjani - 810196662 \\\\\n",
        "Hamid Salemi - 810196479"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6fftGgW3-Hj"
      },
      "source": [
        "# Part 1. Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1NtaXCbGQIi"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from abc import ABC, abstractmethod\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "from torch.optim import lr_scheduler\n",
        "import itertools\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import functools\n",
        "import time"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agDb5PdrICP3"
      },
      "source": [
        "IMG_EXTENSIONS = [\n",
        "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
        "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
        "    '.tif', '.TIF', '.tiff', '.TIFF',\n",
        "]\n",
        "\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFvdyKR-_O33"
      },
      "source": [
        "class ImagePool():\n",
        "    \n",
        "    \n",
        "\n",
        "    def __init__(self, pool_size):\n",
        "        \n",
        "        \n",
        "        self.pool_size = pool_size\n",
        "        if self.pool_size > 0:  # create an empty pool\n",
        "            self.num_imgs = 0\n",
        "            self.images = []\n",
        "\n",
        "    def query(self, images):\n",
        "        \n",
        "        \n",
        "        if self.pool_size == 0:  # if the buffer size is 0, do nothing\n",
        "            return images\n",
        "        return_images = []\n",
        "        for image in images:\n",
        "            image = torch.unsqueeze(image.data, 0)\n",
        "            if self.num_imgs < self.pool_size:   # if the buffer is not full; keep inserting current images to the buffer\n",
        "                self.num_imgs = self.num_imgs + 1\n",
        "                self.images.append(image)\n",
        "                return_images.append(image)\n",
        "            else:\n",
        "                p = random.uniform(0, 1)\n",
        "                if p > 0.5:  # by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer\n",
        "                    random_id = np.random.randint(0, self.pool_size - 1)  # randint is inclusive\n",
        "                    tmp = self.images[random_id].clone()\n",
        "                    self.images[random_id] = image\n",
        "                    return_images.append(tmp)\n",
        "                else:       # by another 50% chance, the buffer will return the current image\n",
        "                    return_images.append(image)\n",
        "        return_images = torch.cat(return_images, 0)   # collect all the images and return\n",
        "        return return_images"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrV8TNUXFo5x"
      },
      "source": [
        "def make_dataset(path, max_size):\n",
        "    images = []\n",
        "    for root, _, fnames in sorted(os.walk(path)):\n",
        "        for fname in fnames:\n",
        "            if is_image_file(fname):\n",
        "                dir = os.path.join(root, fname)\n",
        "                images.append(dir)\n",
        "    return images[:min(max_size, len(images))]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHt5ZP9M30mG"
      },
      "source": [
        "class customDataSet():\n",
        "  def __init__(self, dataroot, phase, max_size, direction, in_channels, out_channels, serial_batches):\n",
        "    self.dir_A = os.path.join(dataroot, phase + 'A')  \n",
        "    self.dir_B = os.path.join(dataroot, phase + 'B')  \n",
        "    self.paths_A = sorted(make_dataset(self.dir_A, max_size))\n",
        "    self.paths_B = sorted(make_dataset(self.dir_B, max_size))\n",
        "    self.A_size = len(self.paths_A)\n",
        "    self.B_size = len(self.paths_B)\n",
        "    btoA = direction == 'BtoA'\n",
        "    input_nc = self.out_channels if btoA else self.in_channels\n",
        "    output_nc = self.in_channels if btoA else self.out_channels\n",
        "    self.serial_batches = serial_batches\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    path_A =  self.paths_A[index % self.A_size]\n",
        "    \n",
        "    if self.serial_batches:\n",
        "      index_B = index%self.B_size\n",
        "    else:\n",
        "      index_B = np.random.randint\n",
        "\n",
        "    B_path = self.B_paths[index_B]\n",
        "    A_img = Image.open(A_path).convert('RGB')\n",
        "    B_img = Image.open(B_path).convert('RGB')\n",
        "\n",
        "    return {'A': A, 'B': B, 'A_paths': A_path, 'B_paths': B_path}\n",
        "\n",
        "  def __len__(self):\n",
        "    return max(self.A_size, self.B_size)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1drajH916X9v"
      },
      "source": [
        "class customDataLoader():\n",
        "\n",
        "  def __init__(self, dataroot, phase, max_size, direction, in_channels, out_channels, serial_batches, batch_size, num_threads):\n",
        "    self.dataset = customDataSet(dataroot, phase, max_size, direction, in_channels, out_channels, serial_batches)\n",
        "    self.dataloader = torch.utils.data.DataLoader(self.dataset, batch_size = batch_size, shuffle=not serial_batches, num_workers=int(num_threads))\n",
        "    self.max_size = max_size\n",
        "    self.batch_size = batch_size\n",
        "  \n",
        "  def load_Data(self):\n",
        "    return self\n",
        "  \n",
        "  def __len__(self):\n",
        "    return(min(len(self.dataset), self.max_size))\n",
        "\n",
        "  def __iter__(self):\n",
        "    for i, data in enumerate(self.dataloader):\n",
        "      if i * self.batch_size >= self.max_size:\n",
        "        break\n",
        "      yield data"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0v5iXqV4ljG"
      },
      "source": [
        "def create_dataset(dataroot, phase, max_size, direction, in_channels, out_channels, serial_batches, batch_size, num_threads):\n",
        "    \n",
        "    \n",
        "    data_loader = customDataLoader(dataroot, phase, max_size, direction, in_channels, out_channels, serial_batches, batch_size, num_threads)\n",
        "    dataset = data_loader.load_data()\n",
        "    return dataset"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdlaPCFjOmfp"
      },
      "source": [
        "# Part 2. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDt7rvzUmSxH"
      },
      "source": [
        "## 2.1 Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyXDBvJimWG5"
      },
      "source": [
        "### 2.1.1. Residual Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgM1PHbtmbm9"
      },
      "source": [
        "class ResnetBlock(nn.Module):\n",
        "  \n",
        "\n",
        "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        \n",
        "        \n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
        "\n",
        "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        \n",
        "        \n",
        "        conv_block = []\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
        "        if use_dropout:\n",
        "            conv_block += [nn.Dropout(0.5)]\n",
        "\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
        "\n",
        "        return nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "        out = x + self.conv_block(x)  # add skip connections\n",
        "        return out"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27jBHB36m29h"
      },
      "source": [
        "### 2.1.2. Resnet-Based Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZQzkGtcm6x9"
      },
      "source": [
        "class ResnetGenerator(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
        "        \n",
        "        assert(n_blocks >= 0)\n",
        "        super(ResnetGenerator, self).__init__()\n",
        "        if type(norm_layer) == functools.partial:\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "        model = [nn.ReflectionPad2d(3),\n",
        "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
        "                 norm_layer(ngf),\n",
        "                 nn.ReLU(True)]\n",
        "\n",
        "        \n",
        "        # add encoder layers\n",
        "        n_downsampling = 2\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2 ** i\n",
        "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
        "                      norm_layer(ngf * mult * 2),\n",
        "                      nn.ReLU(True)]\n",
        "\n",
        "        mult = 2 ** n_downsampling\n",
        "\n",
        "        # add residual blocks\n",
        "        for i in range(n_blocks):\n",
        "\n",
        "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
        "\n",
        "        # add decoder layers\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2 ** (n_downsampling - i)\n",
        "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
        "                                         kernel_size=3, stride=2,\n",
        "                                         padding=1, output_padding=1,\n",
        "                                         bias=use_bias),\n",
        "                      norm_layer(int(ngf * mult / 2)),\n",
        "                      nn.ReLU(True)]\n",
        "        model += [nn.ReflectionPad2d(3)]\n",
        "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
        "        model += [nn.Tanh()]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Standard forward\"\"\"\n",
        "        return self.model(input)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUzRkZV8uuYe"
      },
      "source": [
        "initializing the weights on cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx98ze06utfn"
      },
      "source": [
        "def init_weights(net, init_type='normal', init_gain=0.02):\n",
        "    \n",
        "    def init_func(m):  # define the initialization function\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "            init.normal_(m.weight.data, 0.0, init_gain)\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm2d') != -1:\n",
        "            init.normal_(m.weight.data, 1.0, init_gain)\n",
        "            init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    print('initialize network with %s' % init_type)\n",
        "    net.apply(init_func)  # apply the initialization function <init_func>"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzoDSy5FufQ_"
      },
      "source": [
        "initializing any network on cuda:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VckmlrZkueyH"
      },
      "source": [
        "def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
        "    \n",
        "    if len(gpu_ids) > 0:\n",
        "        assert(torch.cuda.is_available())\n",
        "        net.to(gpu_ids[0])\n",
        "        net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs\n",
        "    init_weights(net, init_type, init_gain=init_gain)\n",
        "    return net"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KspvoIJZwc2n"
      },
      "source": [
        "batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-iXBvFmweRx"
      },
      "source": [
        "def get_norm_layer(norm_type='batch'):\n",
        "    \n",
        "    if norm_type == 'batch':\n",
        "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
        "    else:\n",
        "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
        "    return norm_layer"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MlycOF3wxp-"
      },
      "source": [
        "total generator definition:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VilFed0v9_I"
      },
      "source": [
        "def define_G(input_nc, output_nc, ngf, netG, norm='batch', use_dropout=False, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
        "    \n",
        "    net = None\n",
        "    norm_layer = get_norm_layer(norm_type=norm)\n",
        "\n",
        "    if netG == 'resnet_6blocks':\n",
        "        net = ResnetGenerator(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, n_blocks=6)\n",
        "    else:\n",
        "        raise NotImplementedError('Generator model name [%s] is not recognized' % netG)\n",
        "    return init_net(net, init_type, init_gain, gpu_ids)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2HSJJhYwvmG"
      },
      "source": [
        "## 2.2. Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gua-h6oryl45"
      },
      "source": [
        "### 2.2.1 PatchGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zeW0r6czEA-"
      },
      "source": [
        "PatchGAN definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZJY5PdZy4KG"
      },
      "source": [
        "class NLayerDiscriminator(nn.Module):\n",
        "    \n",
        "    super(NLayerDiscriminator, self).__init__()\n",
        "        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "        kw = 4\n",
        "        padw = 1\n",
        "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
        "        nf_mult = 1\n",
        "        nf_mult_prev = 1\n",
        "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
        "            nf_mult_prev = nf_mult\n",
        "            nf_mult = min(2 ** n, 8)\n",
        "            sequence += [\n",
        "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
        "                norm_layer(ndf * nf_mult),\n",
        "                nn.LeakyReLU(0.2, True)\n",
        "            ]\n",
        "\n",
        "        nf_mult_prev = nf_mult\n",
        "        nf_mult = min(2 ** n_layers, 8)\n",
        "        sequence += [\n",
        "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
        "            norm_layer(ndf * nf_mult),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "\n",
        "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
        "        self.model = nn.Sequential(*sequence)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Standard forward.\"\"\"\n",
        "        return self.model(input)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bezX2BEWzIYe"
      },
      "source": [
        "ParchGAN discriminator initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDttNBZ3ypRh"
      },
      "source": [
        "def define_D(input_nc, ndf, netD, n_layers_D=3, norm='batch', init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
        "    \n",
        "    net = None\n",
        "    norm_layer = get_norm_layer(norm_type=norm)\n",
        "\n",
        "    if netD == 'basic':  # default PatchGAN classifier\n",
        "        net = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer)\n",
        "    else:\n",
        "        raise NotImplementedError('Discriminator model name [%s] is not recognized' % netD)\n",
        "    return init_net(net, init_type, init_gain, gpu_ids)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk4bDt9Ozg7Z"
      },
      "source": [
        "## 2.3. GAN Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51Wwu7U1zjjX"
      },
      "source": [
        "class GANLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, gan_mode, target_real_label=1.0, target_fake_label=0.0):\n",
        "        \n",
        "        super(GANLoss, self).__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
        "        self.gan_mode = gan_mode\n",
        "        if gan_mode == 'lsgan':\n",
        "            self.loss = nn.MSELoss()\n",
        "        else:\n",
        "            raise NotImplementedError('gan mode %s not implemented' % gan_mode)\n",
        "\n",
        "    def get_target_tensor(self, prediction, target_is_real):\n",
        "        \n",
        "        if target_is_real:\n",
        "            target_tensor = self.real_label\n",
        "        else:\n",
        "            target_tensor = self.fake_label\n",
        "        return target_tensor.expand_as(prediction)\n",
        "\n",
        "    def __call__(self, prediction, target_is_real):\n",
        "      \n",
        "      if self.gan_mode in ['lsgan']:\n",
        "            target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
        "            loss = self.loss(prediction, target_tensor)\n",
        "        return loss"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLKZKop11GX3"
      },
      "source": [
        "## 2.4. Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf9oWamd1Sw9"
      },
      "source": [
        "define scheduler:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5j2NXriUN_p"
      },
      "source": [
        "def get_scheduler(optimizer, lr_policy, epoch_count, n_epochs, n_epochs_decay, lr_decay_iters):\n",
        "    \n",
        "    if lr_policy == 'linear':\n",
        "        def lambda_rule(epoch):\n",
        "            lr_l = 1.0 - max(0, epoch + epoch_count - n_epochs) / float(n_epochs_decay + 1)\n",
        "            return lr_l\n",
        "        scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
        "    else:\n",
        "        return NotImplementedError('learning rate policy [%s] is not implemented', lr_policy)\n",
        "    return scheduler"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOtpwTPj1VB2"
      },
      "source": [
        "base model placeholder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKkeannTOmHJ"
      },
      "source": [
        "class BaseModel(ABC):\n",
        "  def __init__(self, gpu_ids, isTrain, checkpoints_dir, name, preprocess, lr_policy, epoch_count, n_epochs, n_epochs_decay, lr_decay_iters, continue_train, load_iter, epoch, verbose):\n",
        "        \n",
        "        self.gpu_ids = gpu_ids\n",
        "        self.isTrain = isTrain\n",
        "        self.device = torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')  # get device name: CPU or GPU\n",
        "        self.save_dir = os.path.join(checkpoints_dir, name)  # save all the checkpoints to save_dir\n",
        "        if preprocess != 'scale_width':  # with [scale_width], input images might have different sizes, which hurts the performance of cudnn.benchmark.\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "        self.loss_names = []\n",
        "        self.model_names = []\n",
        "        self.visual_names = []\n",
        "        self.optimizers = []\n",
        "        self.image_paths = []\n",
        "        self.metric = 0  # used for learning rate policy 'plateau'\n",
        "        self.lr_policy = lr_policy\n",
        "        self.epoch_count = epoch_count\n",
        "        self.n_epochs = n_epochs\n",
        "        self.n_epochs_decay = n_epochs_decay\n",
        "        self.lr_decay_iters = lr_decay_iters\n",
        "        self.continue_iter = continue_iter\n",
        "        self.load_iter = load_iter\n",
        "        self.epoch = epoch\n",
        "        self.verbose = verbose\n",
        "\n",
        "    @abstractmethod\n",
        "    def set_input(self, input):\n",
        "        \n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self):\n",
        "        \n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def optimize_parameters(self):\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def setup(self):\n",
        "        \n",
        "        if self.isTrain:\n",
        "            self.schedulers = [get_scheduler(optimizer, self.lr_policy, self.epoch_count, self.n_epochs, self.n_epochs_decay, self.lr_decay_iters) for optimizer in self.optimizers]\n",
        "        if not self.isTrain or self.continue_train:\n",
        "            load_suffix = 'iter_%d' % self.load_iter if self.load_iter > 0 else self.epoch\n",
        "            self.load_networks(load_suffix)\n",
        "        self.print_networks(self.verbose)\n",
        "\n",
        "    def eval(self):\n",
        "        \n",
        "        for name in self.model_names:\n",
        "            if isinstance(name, str):\n",
        "                net = getattr(self, 'net' + name)\n",
        "                net.eval()\n",
        "\n",
        "    def test(self):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            self.forward()\n",
        "            self.compute_visuals()\n",
        "\n",
        "    def compute_visuals(self):\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def get_image_paths(self):\n",
        "        return self.image_paths\n",
        "\n",
        "    def update_learning_rate(self):\n",
        "        old_lr = self.optimizers[0].param_groups[0]['lr']\n",
        "        for scheduler in self.schedulers:\n",
        "            if self.lr_policy == 'plateau':\n",
        "                scheduler.step(self.metric)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "\n",
        "        lr = self.optimizers[0].param_groups[0]['lr']\n",
        "        print('learning rate %.7f -> %.7f' % (old_lr, lr))\n",
        "\n",
        "    def get_current_visuals(self):\n",
        "        visual_ret = OrderedDict()\n",
        "        for name in self.visual_names:\n",
        "            if isinstance(name, str):\n",
        "                visual_ret[name] = getattr(self, name)\n",
        "        return visual_ret\n",
        "\n",
        "    def get_current_losses(self):\n",
        "        errors_ret = OrderedDict()\n",
        "        for name in self.loss_names:\n",
        "            if isinstance(name, str):\n",
        "                errors_ret[name] = float(getattr(self, 'loss_' + name))  # float(...) works for both scalar tensor and float number\n",
        "        return errors_ret\n",
        "\n",
        "    def save_networks(self, epoch):\n",
        "        for name in self.model_names:\n",
        "            if isinstance(name, str):\n",
        "                save_filename = '%s_net_%s.pth' % (epoch, name)\n",
        "                save_path = os.path.join(self.save_dir, save_filename)\n",
        "                net = getattr(self, 'net' + name)\n",
        "\n",
        "                if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
        "                    torch.save(net.module.cpu().state_dict(), save_path)\n",
        "                    net.cuda(self.gpu_ids[0])\n",
        "                else:\n",
        "                    torch.save(net.cpu().state_dict(), save_path)\n",
        "\n",
        "    def __patch_instance_norm_state_dict(self, state_dict, module, keys, i=0):\n",
        "        key = keys[i]\n",
        "        if i + 1 == len(keys):  # at the end, pointing to a parameter/buffer\n",
        "            if module.__class__.__name__.startswith('InstanceNorm') and \\\n",
        "                    (key == 'running_mean' or key == 'running_var'):\n",
        "                if getattr(module, key) is None:\n",
        "                    state_dict.pop('.'.join(keys))\n",
        "            if module.__class__.__name__.startswith('InstanceNorm') and \\\n",
        "               (key == 'num_batches_tracked'):\n",
        "                state_dict.pop('.'.join(keys))\n",
        "        else:\n",
        "            self.__patch_instance_norm_state_dict(state_dict, getattr(module, key), keys, i + 1)\n",
        "\n",
        "    def load_networks(self, epoch):\n",
        "        for name in self.model_names:\n",
        "            if isinstance(name, str):\n",
        "                load_filename = '%s_net_%s.pth' % (epoch, name)\n",
        "                load_path = os.path.join(self.save_dir, load_filename)\n",
        "                net = getattr(self, 'net' + name)\n",
        "                if isinstance(net, torch.nn.DataParallel):\n",
        "                    net = net.module\n",
        "                print('loading the model from %s' % load_path)\n",
        "                # if you are using PyTorch newer than 0.4 (e.g., built from\n",
        "                # GitHub source), you can remove str() on self.device\n",
        "                state_dict = torch.load(load_path, map_location=str(self.device))\n",
        "                if hasattr(state_dict, '_metadata'):\n",
        "                    del state_dict._metadata\n",
        "\n",
        "                # patch InstanceNorm checkpoints prior to 0.4\n",
        "                for key in list(state_dict.keys()):  # need to copy keys here because we mutate in loop\n",
        "                    self.__patch_instance_norm_state_dict(state_dict, net, key.split('.'))\n",
        "                net.load_state_dict(state_dict)\n",
        "\n",
        "    def print_networks(self, verbose):\n",
        "        print('---------- Networks initialized -------------')\n",
        "        for name in self.model_names:\n",
        "            if isinstance(name, str):\n",
        "                net = getattr(self, 'net' + name)\n",
        "                num_params = 0\n",
        "                for param in net.parameters():\n",
        "                    num_params += param.numel()\n",
        "                if verbose:\n",
        "                    print(net)\n",
        "                print('[Network %s] Total number of parameters : %.3f M' % (name, num_params / 1e6))\n",
        "        print('-----------------------------------------------')\n",
        "\n",
        "    def set_requires_grad(self, nets, requires_grad=False):\n",
        "        if not isinstance(nets, list):\n",
        "            nets = [nets]\n",
        "        for net in nets:\n",
        "            if net is not None:\n",
        "                for param in net.parameters():\n",
        "                    param.requires_grad = requires_grad\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LErrzWCa1aBd"
      },
      "source": [
        "CycleGAN model class, which is a subclass of the base model class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZZnznd3dNow"
      },
      "source": [
        "class CycleGANModel(BaseModel):\n",
        "\n",
        "    def __init__(self, gpu_ids, isTrain, checkpoints_dir, name, preprocess, lr_policy, epoch_count, n_epochs, n_epochs_decay,\n",
        "                 lr_decay_iters, continue_train, load_iter, epoch, verbose, input_nc, output_nc, ngf, netG, norm, no_dropout,\n",
        "                 init_type, init_gain, ndf, netD, n_layers_D, pool_size, gan_mode, lr, beta1, direction):\n",
        "      \n",
        "        BaseModel.__init__(self, gpu_ids, isTrain, checkpoints_dir, name, preprocess, lr_policy, epoch_count, n_epochs, n_epochs_decay, lr_decay_iters, continue_train, load_iter, epoch, verbose, lambda_A = 10.0,\n",
        "                           lambda_B = 10.0, lambda_identity = 0.5)\n",
        "        # specify the training losses you want to print out. The training/test scripts will call <BaseModel.get_current_losses>\n",
        "        self.loss_names = ['D_A', 'G_A', 'cycle_A', 'idt_A', 'D_B', 'G_B', 'cycle_B', 'idt_B']\n",
        "        self.lambda_A = lambda_A\n",
        "        self.lambda_B = lambda_B\n",
        "        self.lambda_identity = lambda_identity\n",
        "        self.direction = direction\n",
        "        # specify the images you want to save/display. The training/test scripts will call <BaseModel.get_current_visuals>\n",
        "        visual_names_A = ['real_A', 'fake_B', 'rec_A']\n",
        "        visual_names_B = ['real_B', 'fake_A', 'rec_B']\n",
        "        if self.isTrain and self.lambda_identity > 0.0:  # if identity loss is used, we also visualize idt_B=G_A(B) ad idt_A=G_A(B)\n",
        "            visual_names_A.append('idt_B')\n",
        "            visual_names_B.append('idt_A')\n",
        "\n",
        "        self.visual_names = visual_names_A + visual_names_B  # combine visualizations for A and B\n",
        "        # specify the models you want to save to the disk. The training/test scripts will call <BaseModel.save_networks> and <BaseModel.load_networks>.\n",
        "        if self.isTrain:\n",
        "            self.model_names = ['G_A', 'G_B', 'D_A', 'D_B']\n",
        "        else:  # during test time, only load Gs\n",
        "            self.model_names = ['G_A', 'G_B']\n",
        "\n",
        "        # define networks (both Generators and discriminators)\n",
        "        # The naming is different from those used in the paper.\n",
        "        # Code (vs. paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)\n",
        "        self.netG_A = define_G(input_nc, output_nc, ngf, netG, norm,\n",
        "                                        not no_dropout, init_type, init_gain, self.gpu_ids)\n",
        "        self.netG_B = define_G(output_nc, input_nc, ngf, netG, norm,\n",
        "                                        not no_dropout, init_type, init_gain, self.gpu_ids)\n",
        "\n",
        "        if self.isTrain:  # define discriminators\n",
        "            self.netD_A = define_D(output_nc, ndf, netD,\n",
        "                                            n_layers_D, norm, init_type, init_gain, self.gpu_ids)\n",
        "            self.netD_B = define_D(input_nc, ndf, netD,\n",
        "                                            n_layers_D, norm, init_type, init_gain, self.gpu_ids)\n",
        "\n",
        "        if self.isTrain:\n",
        "            if self.lambda_identity > 0.0:  # only works when input and output images have the same number of channels\n",
        "                assert(input_nc == output_nc)\n",
        "            self.fake_A_pool = ImagePool(pool_size)  # create image buffer to store previously generated images\n",
        "            self.fake_B_pool = ImagePool(pool_size)  # create image buffer to store previously generated images\n",
        "            # define loss functions\n",
        "            self.criterionGAN = GANLoss(gan_mode).to(self.device)  # define GAN loss.\n",
        "            self.criterionCycle = torch.nn.L1Loss()\n",
        "            self.criterionIdt = torch.nn.L1Loss()\n",
        "            # initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.\n",
        "            self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()), lr=lr, betas=(beta1, 0.999))\n",
        "            self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()), lr=lr, betas=(beta1, 0.999))\n",
        "            self.optimizers.append(self.optimizer_G)\n",
        "            self.optimizers.append(self.optimizer_D)\n",
        "\n",
        "    def set_input(self, input):\n",
        "        AtoB = self.direction == 'AtoB'\n",
        "        self.real_A = input['A' if AtoB else 'B'].to(self.device)\n",
        "        self.real_B = input['B' if AtoB else 'A'].to(self.device)\n",
        "        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n",
        "\n",
        "    def forward(self):\n",
        "        self.fake_B = self.netG_A(self.real_A)  # G_A(A)\n",
        "        self.rec_A = self.netG_B(self.fake_B)   # G_B(G_A(A))\n",
        "        self.fake_A = self.netG_B(self.real_B)  # G_B(B)\n",
        "        self.rec_B = self.netG_A(self.fake_A)   # G_A(G_B(B))\n",
        "\n",
        "    def backward_D_basic(self, netD, real, fake):\n",
        "        # Real\n",
        "        pred_real = netD(real)\n",
        "        loss_D_real = self.criterionGAN(pred_real, True)\n",
        "        # Fake\n",
        "        pred_fake = netD(fake.detach())\n",
        "        loss_D_fake = self.criterionGAN(pred_fake, False)\n",
        "        # Combined loss and calculate gradients\n",
        "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
        "        loss_D.backward()\n",
        "        return loss_D\n",
        "\n",
        "    def backward_D_A(self):\n",
        "        fake_B = self.fake_B_pool.query(self.fake_B)\n",
        "        self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
        "\n",
        "    def backward_D_B(self):\n",
        "        fake_A = self.fake_A_pool.query(self.fake_A)\n",
        "        self.loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n",
        "\n",
        "    def backward_G(self):\n",
        "        lambda_idt = self.lambda_identity\n",
        "        lambda_A = self.lambda_A\n",
        "        lambda_B = self.lambda_B\n",
        "        # Identity loss\n",
        "        if lambda_idt > 0:\n",
        "            # G_A should be identity if real_B is fed: ||G_A(B) - B||\n",
        "            self.idt_A = self.netG_A(self.real_B)\n",
        "            self.loss_idt_A = self.criterionIdt(self.idt_A, self.real_B) * lambda_B * lambda_idt\n",
        "            # G_B should be identity if real_A is fed: ||G_B(A) - A||\n",
        "            self.idt_B = self.netG_B(self.real_A)\n",
        "            self.loss_idt_B = self.criterionIdt(self.idt_B, self.real_A) * lambda_A * lambda_idt\n",
        "        else:\n",
        "            self.loss_idt_A = 0\n",
        "            self.loss_idt_B = 0\n",
        "\n",
        "        # GAN loss D_A(G_A(A))\n",
        "        self.loss_G_A = self.criterionGAN(self.netD_A(self.fake_B), True)\n",
        "        # GAN loss D_B(G_B(B))\n",
        "        self.loss_G_B = self.criterionGAN(self.netD_B(self.fake_A), True)\n",
        "        # Forward cycle loss || G_B(G_A(A)) - A||\n",
        "        self.loss_cycle_A = self.criterionCycle(self.rec_A, self.real_A) * lambda_A\n",
        "        # Backward cycle loss || G_A(G_B(B)) - B||\n",
        "        self.loss_cycle_B = self.criterionCycle(self.rec_B, self.real_B) * lambda_B\n",
        "        # combined loss and calculate gradients\n",
        "        self.loss_G = self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B + self.loss_idt_A + self.loss_idt_B\n",
        "        self.loss_G.backward()\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        # forward\n",
        "        self.forward()      # compute fake images and reconstruction images.\n",
        "        # G_A and G_B\n",
        "        self.set_requires_grad([self.netD_A, self.netD_B], False)  # Ds require no gradients when optimizing Gs\n",
        "        self.optimizer_G.zero_grad()  # set G_A and G_B's gradients to zero\n",
        "        self.backward_G()             # calculate gradients for G_A and G_B\n",
        "        self.optimizer_G.step()       # update G_A and G_B's weights\n",
        "        # D_A and D_B\n",
        "        self.set_requires_grad([self.netD_A, self.netD_B], True)\n",
        "        self.optimizer_D.zero_grad()   # set D_A and D_B's gradients to zero\n",
        "        self.backward_D_A()      # calculate gradients for D_A\n",
        "        self.backward_D_B()      # calculate graidents for D_B\n",
        "        self.optimizer_D.step()  # update D_A and D_B's weights\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhys4iib8QNH"
      },
      "source": [
        "def create_model(self, gpu_ids, isTrain, checkpoints_dir, name, preprocess, lr_policy, epoch_count, n_epochs, n_epochs_decay,\n",
        "                 lr_decay_iters, continue_train, load_iter, epoch, verbose, input_nc, output_nc, ngf, netG, norm, no_dropout,\n",
        "                 init_type, init_gain, ndf, netD, n_layers_D, pool_size, gan_mode, lr, beta1, direction):\n",
        "  \n",
        "    instance = CycleGANModel(gpu_ids, isTrain, checkpoints_dir, name, preprocess, lr_policy, epoch_count, n_epochs, n_epochs_decay,\n",
        "                 lr_decay_iters, continue_train, load_iter, epoch, verbose, input_nc, output_nc, ngf, netG, norm, no_dropout,\n",
        "                 init_type, init_gain, ndf, netD, n_layers_D, pool_size, gan_mode, lr, beta1, direction)\n",
        "    print(\"model was created\")\n",
        "    return instance"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBI1QiZsiyFw"
      },
      "source": [
        "def train_model(\n",
        "    dataroot,\n",
        "    name,\n",
        "    model,\n",
        "    gpu_ids,\n",
        "    checkpoints_dir,\n",
        "    input_nc,\n",
        "    output_nc,\n",
        "    ngf,\n",
        "    ndf,\n",
        "    netD,\n",
        "    netG,\n",
        "    n_layers_D,\n",
        "    norm,\n",
        "    init_type,\n",
        "    init_gain,\n",
        "    no_dropout,\n",
        "    direction,\n",
        "    serial_batches,\n",
        "    num_threads,\n",
        "    batch_size,\n",
        "    max_size,\n",
        "    epoch,\n",
        "    load_iter,\n",
        "    verbose,\n",
        "    display_freq,\n",
        "    display_ncols,\n",
        "    display_id,\n",
        "    phase,\n",
        "    epoch_count,\n",
        "    continue_train,\n",
        "    save_by_iter,\n",
        "    save_epoch_freq,\n",
        "    save_latest_freq,\n",
        "    n_epochs,\n",
        "    n_epochs_decay, \n",
        "    beta1,\n",
        "    lr,\n",
        "    gan_mode,\n",
        "    pool_size,\n",
        "    lr_policy,\n",
        "    lr_decay_iters\n",
        "):\n",
        "       # get training options\n",
        "    dataset = create_dataset(dataroot, phase, max_size, direction, input_nc, output_nc, serial_batches, batch_size, num_threads)  # create a dataset given opt.dataset_mode and other options\n",
        "    dataset_size = len(dataset)    # get the number of images in the dataset.\n",
        "    print('The number of training images = %d' % dataset_size)\n",
        "\n",
        "    model = create_model(gpu_ids, isTrain, checkpoints_dir, name, preprocess, lr_policy, epoch_count, n_epochs, n_epochs_decay,\n",
        "                 lr_decay_iters, continue_train, load_iter, epoch, verbose, input_nc, output_nc, ngf, netG, norm, no_dropout,\n",
        "                 init_type, init_gain, ndf, netD, n_layers_D, pool_size, gan_mode, lr, beta1, direction)      # create a model given opt.model and other options\n",
        "    model.setup()               # regular setup: load and print networks; create schedulers\n",
        "    total_iters = 0                # the total number of training iterations\n",
        "\n",
        "    for epoch in range(opt.epoch_count, opt.n_epochs + opt.n_epochs_decay + 1):    # outer loop for different epochs; we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>\n",
        "        epoch_start_time = time.time()  # timer for entire epoch\n",
        "        iter_data_time = time.time()    # timer for data loading per iteration\n",
        "        epoch_iter = 0                  # the number of training iterations in current epoch, reset to 0 every epoch\n",
        "        model.update_learning_rate()    # update learning rates in the beginning of every epoch.\n",
        "        for i, data in enumerate(dataset):  # inner loop within one epoch\n",
        "            iter_start_time = time.time()  # timer for computation per iteration\n",
        "            if total_iters % opt.print_freq == 0:\n",
        "                t_data = iter_start_time - iter_data_time\n",
        "\n",
        "            total_iters += opt.batch_size\n",
        "            epoch_iter += opt.batch_size\n",
        "            model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
        "            model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
        "\n",
        "            if total_iters % opt.display_freq == 0:   # display images on visdom and save images to a HTML file\n",
        "                save_result = total_iters % opt.update_html_freq == 0\n",
        "                model.compute_visuals()\n",
        "\n",
        "            if total_iters % opt.print_freq == 0:    # print training losses and save logging information to the disk\n",
        "                losses = model.get_current_losses()\n",
        "                t_comp = (time.time() - iter_start_time) / opt.batch_size\n",
        "                visualizer.print_current_losses(epoch, epoch_iter, losses, t_comp, t_data)\n",
        "\n",
        "            if total_iters % opt.save_latest_freq == 0:   # cache our latest model every <save_latest_freq> iterations\n",
        "                print('saving the latest model (epoch %d, total_iters %d)' % (epoch, total_iters))\n",
        "                save_suffix = 'iter_%d' % total_iters if opt.save_by_iter else 'latest'\n",
        "                model.save_networks(save_suffix)\n",
        "\n",
        "            iter_data_time = time.time()\n",
        "        if epoch % opt.save_epoch_freq == 0:              # cache our model every <save_epoch_freq> epochs\n",
        "            print('saving the model at the end of epoch %d, iters %d' % (epoch, total_iters))\n",
        "            model.save_networks('latest')\n",
        "            model.save_networks(epoch)\n",
        "\n",
        "        print('End of epoch %d / %d \\t Time Taken: %d sec' % (epoch, opt.n_epochs + opt.n_epochs_decay, time.time() - epoch_start_time))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny256Mz3-B3m"
      },
      "source": [
        "# Part 3. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocNkeHYoBiy9"
      },
      "source": [
        "## 3.1. Downloading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v94LhUSt-Fgg"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "os.chdir('gdrive/My Drive/NNDL - Spring 00/Mini Project 3')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9OqmPS1AQ4J",
        "outputId": "6118250c-f6ce-4f49-8d8f-d659f2ffc066"
      },
      "source": [
        "!wget -N 'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip' \n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-25 18:52:56--  https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip\n",
            "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.244.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116867962 (111M) [application/zip]\n",
            "Saving to: horse2zebra.zip\n",
            "\n",
            "horse2zebra.zip     100%[===================>] 111.45M  3.60MB/s    in 39s     \n",
            "\n",
            "2021-07-25 18:53:35 (2.85 MB/s) - horse2zebra.zip saved [116867962/116867962]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfiReGBZA4gI"
      },
      "source": [
        "!mkdir ./datasets\n",
        "!mkdir ./datasets/horse2zebra\n",
        "!unzip './datasets/horse2zebra.zip' -d ./datasets/\n",
        "!rm './datasets/horse2zebra.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2lTMe2dBhIa"
      },
      "source": [
        "## 3.2. Specifying the constants needed to run the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW8tNwTzBsNm"
      },
      "source": [
        "dataroot = './datasets/horse2zebra'\n",
        "name = 'horse2zebra'\n",
        "model = 'cycle_gan'\n",
        "gpu_ids = '0'\n",
        "checkpoints_dir = './checkpoints'\n",
        "input_nc = 3\n",
        "output_nc = 3\n",
        "ngf = 65\n",
        "ndf = 64\n",
        "netD = 'basic'\n",
        "netG = 'resnet_6blocks'\n",
        "n_layers_D = 3\n",
        "norm = 'batch'\n",
        "init_type= 'normal'\n",
        "init_gain = 0.02\n",
        "no_dropout = True\n",
        "direction = 'AtoB'\n",
        "serial_batches = True\n",
        "num_threads = 4\n",
        "batch_size = 4\n",
        "max_size = 100\n",
        "epoch = 'latest'\n",
        "load_iter = 0\n",
        "verbose = True\n",
        "display_freq = 50\n",
        "display_ncols = 4\n",
        "display_id = 1\n",
        "phase = 'train'\n",
        "epoch_count= 1\n",
        "continue_train = True\n",
        "save_by_iter = True\n",
        "save_epoch_freq = 5\n",
        "save_latest_freq = 5000\n",
        "n_epochs = 3\n",
        "n_epochs_decay = 2 \n",
        "beta1 = 0.5\n",
        "lr = 0.0002\n",
        "gan_mode = 'lsgan'\n",
        "pool_size = 50\n",
        "lr_policy = 'linear'\n",
        "lr_decay_iters = 2"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ilOB9BbGiZV"
      },
      "source": [
        "train_model(\n",
        "    dataroot,\n",
        "    name,\n",
        "    model,\n",
        "    gpu_ids,\n",
        "    checkpoints_dir,\n",
        "    input_nc,\n",
        "    output_nc,\n",
        "    ngf,\n",
        "    ndf,\n",
        "    netD,\n",
        "    netG,\n",
        "    n_layers_D,\n",
        "    norm,\n",
        "    init_type,\n",
        "    init_gain,\n",
        "    no_dropout,\n",
        "    direction,\n",
        "    serial_batches,\n",
        "    num_threads,\n",
        "    batch_size,\n",
        "    max_size,\n",
        "    epoch,\n",
        "    load_iter,\n",
        "    verbose,\n",
        "    display_freq,\n",
        "    display_ncols,\n",
        "    display_id,\n",
        "    phase,\n",
        "    epoch_count,\n",
        "    continue_train,\n",
        "    save_by_iter,\n",
        "    save_epoch_freq,\n",
        "    save_latest_freq,\n",
        "    n_epochs,\n",
        "    n_epochs_decay, \n",
        "    beta1,\n",
        "    lr,\n",
        "    gan_mode,\n",
        "    pool_size,\n",
        "    lr_policy,\n",
        "    lr_decay_iters\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}