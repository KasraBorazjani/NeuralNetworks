{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q3 - Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZrnr7qa3wee",
        "outputId": "5f4c8947-53d9-4924-a6e0-3d6feea861db"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ECmRwq081su",
        "outputId": "1f21f857-a91b-4997-e7e4-df805bddfceb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.chdir('gdrive/My Drive/NNDL - Spring 00/Mini Project 2')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsAJj9ku9kZv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCSIpkMk9ce0"
      },
      "source": [
        "## Part 1. Resolving the Unbalancedness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaVOLpMk9hIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62410b10-c976-477e-ec7b-97eea5192724"
      },
      "source": [
        "dataset = pd.read_csv('sentiment_final.csv')\n",
        "print(dataset['sentiment'].value_counts())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative    8493\n",
            "Positive    2236\n",
            "Name: sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DhLxT4xFqQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864a7a9c-4547-48aa-b329-211e49b13027"
      },
      "source": [
        "dataset_copy = dataset[dataset['sentiment']=='Positive']\n",
        "print(dataset_copy)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text sentiment\n",
            "0      RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
            "1      RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
            "2      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
            "3      RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
            "8      RT @WayneDupreeShow: Just woke up to tweet thi...  Positive\n",
            "...                                                  ...       ...\n",
            "10717  Best line of #GOPDebate was \"Immigration witho...  Positive\n",
            "10720  RT @RWSurferGirl: Trump has got it right, nobo...  Positive\n",
            "10725  RT @georgehenryw: Who thought Huckabee exceede...  Positive\n",
            "10726  RT @Lrihendry: #TedCruz As President, I will a...  Positive\n",
            "10728  RT @Lrihendry: #TedCruz headed into the Presid...  Positive\n",
            "\n",
            "[2236 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFRAGJHrG23L"
      },
      "source": [
        "os_list = []\n",
        "for i in range(len(dataset_copy)):\n",
        "  inst_loc = np.random.randint(len(dataset_copy), size=1)\n",
        "  os_list.append([dataset_copy['text'].iloc[inst_loc[0]], dataset_copy['sentiment'].iloc[inst_loc[0]]])\n",
        "\n",
        "os_list = pd.DataFrame(os_list, columns=['text', 'sentiment'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y55M2HDTOSl5",
        "outputId": "7059162b-60e3-484a-adb0-fd6e1b550bc0"
      },
      "source": [
        "dataset_neg_us = dataset[dataset['sentiment']=='Negative']\n",
        "print(dataset_neg_us)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text sentiment\n",
            "4      RT @warriorwoman91: I liked her and was happy ...  Negative\n",
            "5      Deer in the headlights RT @lizzwinstead: Ben C...  Negative\n",
            "6      RT @NancyOsborne180: Last night's debate prove...  Negative\n",
            "7      @JGreenDC @realDonaldTrump In all fairness #Bi...  Negative\n",
            "9      Me reading my family's comments about how grea...  Negative\n",
            "...                                                  ...       ...\n",
            "10721  So trans soldiers can die for you Huckabee but...  Negative\n",
            "10722  RT @RWSurferGirl: Is it just me or does anyone...  Negative\n",
            "10723  RT @RWSurferGirl: Fox is cherry picking the ca...  Negative\n",
            "10724  RT @cappy_yarbrough: Love to see men who will ...  Negative\n",
            "10727  RT @JRehling: #GOPDebate Donald Trump says tha...  Negative\n",
            "\n",
            "[8493 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BauTIU1QNeY",
        "outputId": "97c78960-12ef-4896-f55b-a8753d7a9c98"
      },
      "source": [
        "for i in range(int(0.5*len(dataset_neg_us))):\n",
        "  inst_loc = np.random.randint(len(dataset_neg_us), size=1)\n",
        "  dataset_neg_us.drop(index=dataset_neg_us.index[inst_loc[0]], inplace=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ardXeYdxRTon"
      },
      "source": [
        "dataset_copy = dataset_copy.append(os_list)\n",
        "dataset_copy = dataset_copy.append(dataset_neg_us)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAhwdX_KRrdA",
        "outputId": "9e8b9341-b2a1-4465-f8bc-22f42350119f"
      },
      "source": [
        "print(dataset_copy)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text sentiment\n",
            "0      RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
            "1      RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n",
            "2      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n",
            "3      RT @GregAbbott_TX: @TedCruz: \"On my first day ...  Positive\n",
            "8      RT @WayneDupreeShow: Just woke up to tweet thi...  Positive\n",
            "...                                                  ...       ...\n",
            "10713  while pro-life nonsense @ the #GOPDebate was n...  Negative\n",
            "10714  GOP respects life....just not black ones. #GOP...  Negative\n",
            "10719  RT @RWSurferGirl: Why should @realDonaldTrump ...  Negative\n",
            "10721  So trans soldiers can die for you Huckabee but...  Negative\n",
            "10724  RT @cappy_yarbrough: Love to see men who will ...  Negative\n",
            "\n",
            "[8719 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyAme7maUlLB"
      },
      "source": [
        "## Part 2. Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN9V7MmeUqi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d4988f-12d9-4a0e-a034-e116f6398b2f"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LNH4hK3qXbL"
      },
      "source": [
        "def tokenize(sentences, stop_words):\n",
        "  lowercases = sentences.lower() #setting all words to lowercase\n",
        "  nopunc = \"\".join([word for word in lowercases if word not in string.punctuation]) #Removing punctuations\n",
        "  alphanum = re.sub('\\W+', ' ', nopunc) #Removing non-alphaumeric characters\n",
        "  tokens = nltk.word_tokenize(alphanum) # tokenizing\n",
        "  tokens = [word for word in tokens if word not in stop_words] #Removing stopwords\n",
        "  tokens = [word for word in tokens if '@' not in word] # Removing the '@'s\n",
        "  tokens = [word for word in tokens if 'http' not in word] #Removing URLs\n",
        "  tokens = [word for word in tokens if word not in ['rt', 'gopdebate'] and len(word)>1]\n",
        "\n",
        "  return tokens"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQJEDlmj0TMQ"
      },
      "source": [
        " dataset_copy['tokens'] = dataset_copy['text'].map(lambda x: tokenize(x,stop_words))\n",
        " clean_dataset = dataset_copy.loc[dataset_copy.tokens.map(lambda x: len(x)>0),['text', 'sentiment', 'tokens']]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swiODgXm2hXT",
        "outputId": "de8dfa16-c79f-4c0f-914a-25bf0a154775"
      },
      "source": [
        "print(clean_dataset)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text  ...                                             tokens\n",
            "0      RT @ScottWalker: Didn't catch the full #GOPdeb...  ...  [scottwalker, didnt, catch, full, last, night,...\n",
            "1      RT @RobGeorge: That Carly Fiorina is trending ...  ...  [robgeorge, carly, fiorina, trending, hours, d...\n",
            "2      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  ...  [danscavino, realdonaldtrump, delivered, highe...\n",
            "3      RT @GregAbbott_TX: @TedCruz: \"On my first day ...  ...  [gregabbotttx, tedcruz, first, day, rescind, e...\n",
            "8      RT @WayneDupreeShow: Just woke up to tweet thi...  ...  [waynedupreeshow, woke, tweet, best, line, nig...\n",
            "...                                                  ...  ...                                                ...\n",
            "10713  while pro-life nonsense @ the #GOPDebate was n...  ...  [prolife, nonsense, amusing, notion, jizzisape...\n",
            "10714  GOP respects life....just not black ones. #GOP...  ...  [gop, respects, lifejust, black, ones, gopdeba...\n",
            "10719  RT @RWSurferGirl: Why should @realDonaldTrump ...  ...  [rwsurfergirl, realdonaldtrump, pledge, suppor...\n",
            "10721  So trans soldiers can die for you Huckabee but...  ...  [trans, soldiers, die, huckabee, cant, foot, b...\n",
            "10724  RT @cappy_yarbrough: Love to see men who will ...  ...  [cappyyarbrough, love, see, men, never, faced,...\n",
            "\n",
            "[8719 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DDr6BNx9Xvl",
        "outputId": "9c26da68-2f85-42df-81ec-b807ab375998"
      },
      "source": [
        "clean_dataset['sentences'] = clean_dataset.tokens.map(lambda x: \" \".join(word for word in x))\n",
        "print(clean_dataset['sentences'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        scottwalker didnt catch full last night scotts...\n",
            "1        robgeorge carly fiorina trending hours debate ...\n",
            "2        danscavino realdonaldtrump delivered highest r...\n",
            "3        gregabbotttx tedcruz first day rescind every i...\n",
            "8        waynedupreeshow woke tweet best line night via...\n",
            "                               ...                        \n",
            "10713    prolife nonsense amusing notion jizzisaperson ...\n",
            "10714          gop respects lifejust black ones gopdebates\n",
            "10719    rwsurfergirl realdonaldtrump pledge support go...\n",
            "10721    trans soldiers die huckabee cant foot bill mak...\n",
            "10724    cappyyarbrough love see men never faced pregna...\n",
            "Name: sentences, Length: 8719, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQWpYg0P-WT_",
        "outputId": "3452ccc3-0d3a-4645-db3b-c2641cb949a2"
      },
      "source": [
        "print(clean_dataset['sentences'].iloc[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scottwalker didnt catch full last night scotts best lines 90 seconds walker16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDL8rk50SbkT"
      },
      "source": [
        "## Part 3. Using Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "aXXd-NR_VVPo",
        "outputId": "166dfa1d-bbc0-49e7-985c-32ad3e543c7e"
      },
      "source": [
        "clean_dataset['sentiment'] = clean_dataset['sentiment'].astype('category')\n",
        "clean_dataset['sentiment_enc'] = clean_dataset['sentiment'].cat.codes\n",
        "clean_dataset.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tokens</th>\n",
              "      <th>sentences</th>\n",
              "      <th>sentiment_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[scottwalker, didnt, catch, full, last, night,...</td>\n",
              "      <td>scottwalker didnt catch full last night scotts...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[robgeorge, carly, fiorina, trending, hours, d...</td>\n",
              "      <td>robgeorge carly fiorina trending hours debate ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[danscavino, realdonaldtrump, delivered, highe...</td>\n",
              "      <td>danscavino realdonaldtrump delivered highest r...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @GregAbbott_TX: @TedCruz: \"On my first day ...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[gregabbotttx, tedcruz, first, day, rescind, e...</td>\n",
              "      <td>gregabbotttx tedcruz first day rescind every i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RT @WayneDupreeShow: Just woke up to tweet thi...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>[waynedupreeshow, woke, tweet, best, line, nig...</td>\n",
              "      <td>waynedupreeshow woke tweet best line night via...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ... sentiment_enc\n",
              "0  RT @ScottWalker: Didn't catch the full #GOPdeb...  ...             1\n",
              "1  RT @RobGeorge: That Carly Fiorina is trending ...  ...             1\n",
              "2  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  ...             1\n",
              "3  RT @GregAbbott_TX: @TedCruz: \"On my first day ...  ...             1\n",
              "8  RT @WayneDupreeShow: Just woke up to tweet thi...  ...             1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIOrX7yTGC1p"
      },
      "source": [
        "def pad_words(review, seq_len):\n",
        "  review_len = len(review)\n",
        "  if review_len <= seq_len:\n",
        "    return np.append(review, seq_len-review_len *np.zeros((64,64)))\n",
        "  \n",
        "  elif review_len < seq_len:\n",
        "    return review[0:seq_len]\n",
        "  "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2u14T8IGFR3"
      },
      "source": [
        "clean_dataset['padvec'] = clean_dataset['tokens'].map(lambda x: pad_words(x, 10))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KZM4AMtrf7F"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "tokenized_docs = clean_dataset['tokens']\n",
        "model = Word2Vec(sentences=tokenized_docs, size=64, seed=42, workers=1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gco0tUZevSgK"
      },
      "source": [
        "def vectorize(docs, model):\n",
        "\n",
        "  zerovec = np.zeros(model.vector_size)\n",
        "  sentence_words = []\n",
        "  for word in docs:\n",
        "    if word in model.wv:\n",
        "      try:\n",
        "        sentence_words.append(model.wv[word])\n",
        "      except KeyError:\n",
        "        continue\n",
        "    \n",
        "  if sentence_words:\n",
        "    return sentence_words\n",
        "  else:\n",
        "    return zerovec"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NRhf7V4wVq_"
      },
      "source": [
        "clean_dataset['vectors'] = clean_dataset['padvec'].map(lambda x: vectorize(x, model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2EpwO6wyIcG",
        "outputId": "b0daf3c5-6cc3-4cf2-c37e-9ab869aa8977"
      },
      "source": [
        "print(clean_dataset.padvec.iloc[0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDwSl-i7CJPo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "zXf9VO-WCgXW",
        "outputId": "833579a2-81ee-4776-b924-cf0e00e62af9"
      },
      "source": [
        "print(len(clean_dataset.padvec.iloc[0]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-801981112648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    }
  ]
}